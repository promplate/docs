---
title: Quick Start
description: Let's begin Prompting in 1 minute
---

<script>
import CodeBlock from "$lib/components/CodeBlock.svelte"
import Details from "$lib/components/Details.svelte"
</script>

### Installation with `pip install` 

Directly install from [PyPI](https://pypi.org/project/promplate/):

```
pip install promplate[openai]
```

We are using `OpenAI` just for demonstration. In fact, **you can use any LLM as you want**.

### Make LLM Calls

First, **Open a python REPL** ðŸ’»

(`ipython` or `jupyter` are OK. Just any REPL you like)

<CodeBlock code={`
>>> from promplate.llm.openai import ChatComplete  # this simply wraps OpenAI's SDK
>>> complete = ChatComplete(model="gpt-3.5-turbo", api_key="...")
`.trim()} />

> The `api_key` should be filled with your API Key from [OpenAI Platform](https://platform.openai.com/account/api-keys)

Then call it simply with a string:

<CodeBlock code={`
>>> complete("hi")
'Hello! How can I assist you today?'
`.trim()} />

<Details summary="If you don't have an OpenAI API Key ðŸ”‘">
You could use our FREE proxy site as <code>api_base</code> like this:
<CodeBlock code={`
>>> from promplate.llm.openai import ChatComplete
>>> complete = ChatComplete(model="gpt-3.5-turbo", api_base="https://promplate.dev")
>>> complete("hi")  # this simply wraps OpenAI's SDK
'Hello! How can I assist you today?'
`.trim()} />
</Details>

<Details summary="If you want to use instruct models ðŸ¤”">
Simply replace <code>ChatComplete</code> by <code>TextComplete</code>:
<CodeBlock code={`
>>> from promplate.llm.openai import TextComplete
>>> complete = TextComplete(model="gpt-3.5-turbo-instruct", api_key="...")
>>> complete("I am")
' just incredibly proud of the team, and their creation of a brand new ship makes'
`.trim()} />
And you can pass parameters when calling a <code>Complete</code> instance:
<CodeBlock code={`
>>> complete("1 + 1 = ", temperature=0, max_tokens=1)
'2'
`.trim()} />
</Details>

<Details summary="If you prefer to stream the response ðŸ‘€">
It is still super easy, just use <code>ChatGenerate</code>:
<CodeBlock code={`
>>> from promplate.llm.openai import ChatGenerate
>>> generate = ChatGenerate(model="gpt-3.5-turbo", api_key="...")
>>> for i in generate("Explain why 1 + 1 = 2"):
...     print(i, end="", flush=True)  # this will print generated tokens gradually
...
The equation 1 + 1 = 2 is a fundamental principle in mathematics and arithmetic. It represents the addition operation, which involves combining two quantities or numbers to find their sum.\n
In this case, when we add 1 to another 1, we are essentially combining or merging two individual units or quantities. By doing this, we end up with a total count of two. Therefore, the result is 2.\n
This principle is consistent and holds true in all contexts and across different number systems, whether it is in the base-10 decimal system, binary system, or any other number system.\n
1 + 1 = 2 is considered a basic and universally accepted mathematical fact, forming the foundation for more complex mathematical operations and calculations.\n
`.trim()} />
</Details>
